{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5bc9be56",
   "metadata": {},
   "source": [
    "## Sentiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "818b3b52",
   "metadata": {},
   "source": [
    "In this exercise we use the IMDb-dataset, which we will use to perform a sentiment analysis. The code below assumes that the data is placed in the same folder as this notebook. We see that the reviews are loaded as a pandas dataframe, and print the beginning of the first few reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "67da3bc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "                                                   0\n",
      "0  bromwell high is a cartoon comedy . it ran at ...\n",
      "1  story of a man who has unnatural feelings for ...\n",
      "2  homelessness  or houselessness as george carli...\n",
      "3  airport    starts as a brand new luxury    pla...\n",
      "4  brilliant over  acting by lesley ann warren . ...\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "reviews = pd.read_csv('reviews.txt', header=None)\n",
    "labels = pd.read_csv('labels.txt', header=None)\n",
    "Y = (labels=='positive').astype(np.int_)\n",
    "\n",
    "print(type(reviews))\n",
    "print(reviews.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4982b946",
   "metadata": {},
   "source": [
    "**(a)** Split the reviews and labels in test, train and validation sets. The train and validation sets will be used to train your model and tune hyperparameters, the test set will be saved for testing. Use the `CountVectorizer` from `sklearn.feature_extraction.text` to create a Bag-of-Words representation of the reviews. Only use the 10,000 most frequent words (use the `max_features`-parameter of `CountVectorizer`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a25a5242",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set shape: (20000, 10000)\n",
      "Validation set shape: (4000, 10000)\n",
      "Test set shape: (1000, 10000)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Splitting the data into train, validation, and test sets\n",
    "X_train, X_temp, Y_train, Y_temp = train_test_split(reviews, Y, test_size=0.2, random_state=42)\n",
    "X_val, X_test, Y_val, Y_test = train_test_split(X_temp, Y_temp, test_size=0.2, random_state=42)\n",
    "\n",
    "# Creating a Bag-of-Words representation\n",
    "vectorizer = CountVectorizer(max_features=10000)\n",
    "X_train_bow = vectorizer.fit_transform(X_train.values.ravel())\n",
    "X_val_bow = vectorizer.transform(X_val.values.ravel())\n",
    "X_test_bow = vectorizer.transform(X_test.values.ravel())\n",
    "\n",
    "print(\"Train set shape:\", X_train_bow.shape)\n",
    "print(\"Validation set shape:\", X_val_bow.shape)\n",
    "print(\"Test set shape:\", X_test_bow.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebf07ee9",
   "metadata": {},
   "source": [
    "**(b)** Explore the representation of the reviews. How is a single word represented? How about a whole review?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fc874036",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector representation of a single word:  (array([0], dtype=int32), array([136], dtype=int32))\n",
      "\n",
      "Vector representation of a whole review:  (array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0], dtype=int32), array([8962, 4391, 6190, 5433, 5717,   16,  846, 7845, 9090, 5576,  509,\n",
      "       6233, 5828, 4642, 3751, 6775, 9668, 5873, 4729, 4716, 8972, 8960,\n",
      "       4086, 6100,  786, 3175, 5882, 9964, 4330, 5430, 9005, 7902, 8617,\n",
      "       9856, 1624, 8468,  279, 2769, 2025, 5872, 9780, 2503, 1972, 6500,\n",
      "       4056, 1056, 5362, 3758, 4123, 4169, 4369, 9790, 2601, 2472, 4476,\n",
      "       7642,  334,  178, 7984, 8602, 8758, 3399, 4813,  557,  308,  723,\n",
      "       9894, 3512, 1963, 4197, 6203, 9160, 3247, 5333, 6824,  256, 8676,\n",
      "       9292, 9442,  183, 1730, 6231, 9716, 9514, 7849, 6232, 9123, 6211,\n",
      "       6662, 8968, 7559, 7067, 9748, 6024, 7184, 7848, 1953, 8275, 7187,\n",
      "        291, 8284, 5067, 3794, 7494, 2909, 7159, 7754, 4874, 2469,   83,\n",
      "       6647,  215, 5188, 7152, 8283, 3112, 5954, 8996, 4046, 7684, 6619,\n",
      "       9408, 9970,  874, 3255, 9947, 8686, 8359, 9975, 5795, 8280, 2888,\n",
      "       1521, 4383, 2054, 1113, 5323, 7717, 6306], dtype=int32))\n"
     ]
    }
   ],
   "source": [
    "word = vectorizer.get_feature_names_out()[136]\n",
    "\n",
    "print(\"Vector representation of a single word: \", vectorizer.transform([word]).nonzero())\n",
    "print(\"\\nVector representation of a whole review: \", X_train_bow[0].nonzero())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2638fce",
   "metadata": {},
   "source": [
    "**(c)** Train a neural network with a single hidden layer on the dataset, tuning the relevant hyperparameters to optimize accuracy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9816b740",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python312\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1124: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP Accuracy:  0.869\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "model = MLPClassifier(max_iter=1000, random_state=42)\n",
    "\n",
    "param_grid = {\n",
    "    'hidden_layer_sizes': [(50,), (100,), (150,), (100, 50)],\n",
    "    'activation': ['relu', 'tanh'],\n",
    "    'alpha': [0.0001, 0.001, 0.01],  \n",
    "    'learning_rate_init': [0.001, 0.01],\n",
    "}\n",
    "\n",
    "# grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=3, scoring='accuracy', n_jobs=-1)\n",
    "# grid_search.fit(X_train_bow, Y_train)\n",
    "# best_model = grid_search.best_estimator_\n",
    "# Y_pred_best_model = best_model.predict(X_test_bow)\n",
    "# print(\"Best MLP Hyperparameters:\", grid_search.best_params_)\n",
    "\n",
    "# To save computation time, using best parameters from a previous run:\n",
    "best_params = {\n",
    "    'hidden_layer_sizes': (100,),\n",
    "    'activation': 'relu',\n",
    "    'alpha': 0.0001,\n",
    "    'learning_rate_init': 0.001\n",
    "}\n",
    "\n",
    "model = MLPClassifier(max_iter=1000, random_state=42, **best_params)\n",
    "model.fit(X_train_bow, Y_train)\n",
    "Y_valid_pred = model.predict(X_val_bow)\n",
    "\n",
    "accuracy = accuracy_score(Y_val, Y_valid_pred)\n",
    "print(\"MLP Accuracy: \", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "500a7069",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python312\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1124: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy:  0.869\n"
     ]
    }
   ],
   "source": [
    "#Second approach without the hyperparameters from the grid search\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Creating a neural network classifier\n",
    "model = MLPClassifier(hidden_layer_sizes=(100,), max_iter=1000, random_state=42)\n",
    "\n",
    "# Training on the training data\n",
    "model.fit(X_train_bow, Y_train)\n",
    "\n",
    "# Evaluating on the validation set\n",
    "Y_valid_pred = model.predict(X_val_bow)\n",
    "\n",
    "accuracy = accuracy_score(Y_val, Y_valid_pred)\n",
    "print(\"Validation accuracy: \", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fd327a6",
   "metadata": {},
   "source": [
    "**(d)** Test your sentiment-classifier on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c62c8204",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.8640\n"
     ]
    }
   ],
   "source": [
    "#Evaluating on the test set\n",
    "Y_test_pred = model.predict(X_test_bow)\n",
    "accuracy = accuracy_score(Y_test, Y_test_pred)\n",
    "print(f\"Test accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd44ee62",
   "metadata": {},
   "source": [
    "**(e)** Use the classifier to classify a few sentences you write yourselves. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1ef2970",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review: This movie was absolutely wonderful and touching.\n",
      "Predicted sentiment: positive\n",
      "\n",
      "Review: I hated every minute of this film.\n",
      "Predicted sentiment: negative\n",
      "\n",
      "Review: An average film with a few good moments.\n",
      "Predicted sentiment: positive\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Classifying a new review\n",
    "new_review = [\n",
    "    \"This movie was absolutely wonderful and touching.\",\n",
    "    \"I hated every minute of this film.\",\n",
    "    \"An average film with a few good moments.\",\n",
    "]\n",
    "new_review_bow = vectorizer.transform(new_review)\n",
    "new_review_pred = model.predict(new_review_bow)\n",
    "\n",
    "for review, pred in zip(new_review, new_review_pred):\n",
    "    label = \"positive\" if pred == 1 else \"negative\"\n",
    "    print(f\"Review: {review}\\nPredicted sentiment: {label}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
